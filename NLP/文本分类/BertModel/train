import os
import time

import torch
import torch.nn as nn
from transformers import BertTokenizer, AdamW, BertConfig
from torch.utils.data import DataLoader
from model import BertClassifier, LstmClassifier, BertLstmClassifier
from dataset import CNewsDataset


# from tqdm import tqdm


def main():
    # 参数设置
    batch_size = 2
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    epochs = 20
    learning_rate = 5e-5  # Learning Rate不宜太大

    # 获取到dataset
    train_data = CNewsDataset('data/cnews/train.txt')  # data/cnews/demo_train.txt   cnews.train.txt
    # valid_dataset = CNewsDataset('data/cnews/cnews.val.txt')  # data/cnews/demo_val.txt

    train_size = int(len(train_data) * 0.7)
    validate_size = int(len(train_data) * 0.3)
    test_size = len(train_data) - validate_size - train_size

    train_dataset, validate_dataset, test_dataset = \
        torch.utils.data.random_split(train_data, [train_size, validate_size, test_size],
                                      generator=torch.Generator().manual_seed(36))

    train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)
    eval_dataloader = DataLoader(validate_dataset, batch_size=2, shuffle=True)

    # 读取BERT的配置文件
    bert_config = BertConfig.from_pretrained('clue/albert_chinese_tiny')
    # print("bert_config:", bert_config.num_labels)
    num_labels = len(train_data.labels)
    # print("num_labels:", num_labels)
    # 初始化模型
    model = BertLstmClassifier(bert_config, num_labels).to(device)

    # 优化器
    optimizer = AdamW(model.parameters(), lr=learning_rate)
    # 损失函数
    criterion = nn.CrossEntropyLoss()

    best_acc = 0

    start_time = time.time()
    for epoch in range(1, epochs + 1):
        losses = 0  # 损失
        accuracy = 0  # 准确率

        model.train()

        for x, y in enumerate(train_dataloader):
            # 梯度清零
            model.zero_grad()
            # print("input_ids:", x)
            # print("input_ids:", y)
            # 显示训练进度
            # train_bar.set_description('Epoch %i train' % epoch)
            input_ids = y[0]
            # attention_mask = y[1]
            # token_type_ids = y[2]
            label_id = y[1]
            input_pos = y[2]
            input_vocabulary = y[3]
            # print("input_vocabulary:", input_vocabulary)
            # 传入数据，调用model.forward()
            output = model(
                input_ids=input_ids.to(device),
                input_pos=input_pos.to(device),
                input_vocabulary=input_vocabulary.to(device),
            )
            # print("output:", output)
            # print("label_id:", label_id)
            # 计算loss

            loss = criterion(output, label_id.to(device))

            losses += loss.item()

            pred_labels = torch.argmax(output, dim=1)  # 预测出的label

            acc = torch.sum(pred_labels == label_id.to(device)).item() / len(pred_labels)  # acc
            accuracy += acc

            loss.backward()
            optimizer.step()
            # train_bar.set_postfix(loss=loss.item(), acc=acc)

        average_loss = losses / len(train_dataloader)
        average_acc = accuracy / len(train_dataloader)

        print('Epoch:', epoch, '\tTrain ACC:', average_acc, '\tLoss:', average_loss)

        # 验证
        model.eval()
        losses = 0  # 损失
        accuracy = 0  # 准确率
        # valid_bar = tqdm(valid_dataloader, ncols=100)
        print('# 验证')
        for x, y in enumerate(eval_dataloader):
            # valid_bar.set_description('Epoch %i valid' % epoch)
            input_ids = y[0]
            # attention_mask = y[1]
            # token_type_ids = y[2]
            label_id = y[1]
            input_pos = y[2]
            input_vocabulary = y[3]
            output = model(
                input_ids=input_ids.to(device),
                # attention_mask=attention_mask.to(device),
                # token_type_ids=token_type_ids.to(device),
                input_pos=input_pos.to(device),
                input_vocabulary=input_vocabulary.to(device),
            )

            loss = criterion(output, label_id.to(device))

            losses += loss.item()

            pred_labels = torch.argmax(output, dim=1)  # 预测出的label

            acc = torch.sum(pred_labels == label_id.to(device)).item() / len(pred_labels)  # acc
            accuracy += acc
            # valid_bar.set_postfix(loss=loss.item(), acc=acc)

        average_loss = losses / len(eval_dataloader)
        average_acc = accuracy / len(eval_dataloader)

        print('\tValid ACC:', average_acc, '\tLoss:', average_loss)

        if not os.path.exists('models'):
            os.makedirs('models')

        # 判断并保存验证集上表现最好的模型
        if average_acc > best_acc:
            best_acc = average_acc
            torch.save(model.state_dict(), 'models/best_model.pkl')
    run_time = time.time() - start_time
    print("run_time:", run_time / 3600, 'h')


if __name__ == '__main__':
    main()
